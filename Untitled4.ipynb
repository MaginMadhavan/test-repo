{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "mount_file_id": "1MZz7Rg8A3At440Ejc95de_38ROPM6Ax-",
      "authorship_tag": "ABX9TyOeqBjmbPRDRN9rtlZrWSzQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaginMadhavan/test-repo/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Face emotion recognition and gender classification"
      ],
      "metadata": {
        "id": "St7lvOAhC4Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files=os.listdir(fldr)\n",
        ">>\n",
        "['fear', 'contempt', 'happy', 'anger', 'surprise', 'disgust', 'sadness']\n",
        "Exp=['fear', 'contempt', 'happy', 'anger', 'surprise', 'disgust', 'sadness']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "KhwtpRqYDDsZ",
        "outputId": "187e11fd-d70a-41b4-e273-0deb2946508a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-88ac2842247f>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    >>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "i=0\n",
        "last=[]\n",
        "images=[]\n",
        "labels=[]\n",
        "for fle in files:\n",
        "  idx=Exp.index(fle)\n",
        "  label=idx\n",
        "  \n",
        "  total=fldr+'/'+fle\n",
        "  files_exp= os.listdir(total)\n",
        "  for fle_2 in files_exp:\n",
        "    file_main=total+'/'+fle_2\n",
        "    print(file_main+\"   \"+str(label))\n",
        "    image= cv2.imread(file_main)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image= cv2.resize(image,(48,48))\n",
        "    images.append(image)\n",
        "    labels.append(label)\n",
        "    i+=1\n",
        "  last.append(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "R4seJzOhDGlt",
        "outputId": "7f974e05-97de-48ee-b9be-c036da273e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b6f56189bd21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mExp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np \n",
        "images_f=np.array(images)\n",
        "labels_f=np.array(labels)\n",
        "images_f_2=images_f/255\n",
        "labels_encoded=tf.keras.utils.to_categorical(labels_f,num_classes=num_of_classes)\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(images_f_2, labels_encoded,test_size=0.25)"
      ],
      "metadata": {
        "id": "FztrF4-0EDrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n",
        "from tensorflow.keras.layers import Input,Activation,Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def Convolution(input_tensor,filters):\n",
        "    \n",
        "    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001))(input_tensor)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x= Activation('relu')(x)\n",
        "    return x\n",
        "def model(input_shape):\n",
        "  inputs = Input((input_shape))\n",
        "  \n",
        "  conv_1= Convolution(inputs,32)\n",
        "  maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)\n",
        "  conv_2 = Convolution(maxp_1,64)\n",
        "  maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)\n",
        "  conv_3 = Convolution(maxp_2,128)\n",
        "  maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)\n",
        "  conv_4 = Convolution(maxp_3,256)\n",
        "  maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)\n",
        "  flatten= Flatten() (maxp_4)\n",
        "  dense_1= Dense(128,activation='relu')(flatten)\n",
        "  drop_1=Dropout(0.2)(dense_1)\n",
        "  output= Dense(7,activation=\"sigmoid\")(drop_1)\n",
        "  model = Model(inputs=[inputs], outputs=[output])\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "r7IMQfa76JOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "History=Model.fit(X_train,Y_train,batch_size=32,validation_data=(X_test,Y_test),epochs=1000,callbacks=[callback_list])\n"
      ],
      "metadata": {
        "id": "Ds6vIYQ96NQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pred=Model.predict(X_test)\n",
        "Pred\n",
        ">>\n",
        "array([[1.68134073e-09, 5.25928086e-11, 5.46700324e-11, ...,         7.71565616e-01, 8.71616357e-05, 4.54742303e-06],        [5.06911943e-11, 5.20724059e-17, 2.85400745e-07, ...,         2.65912314e-12, 7.78120279e-01, 2.07833662e-14],        [5.95332267e-07, 7.41830490e-07, 1.73864496e-08, ...,         4.54492539e-01, 9.06203127e-07, 1.08237209e-05],        ...,        [1.56573861e-07, 3.44979071e-07, 3.86641860e-01, ...,         3.84031367e-08, 4.99448021e-08, 6.93729362e-13],        [1.91495033e-07, 7.53485918e-01, 1.24115175e-07, ...,         2.53645931e-06, 6.98523905e-09, 2.22882386e-06],        [5.07813091e-14, 1.79454021e-12, 1.35435105e-14, ...,         9.94049311e-01, 2.74002265e-09, 1.31444740e-08]], dtype=float32)"
      ],
      "metadata": {
        "id": "AXCbGBOa6Xhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0 Y_test_l=[] \n",
        "Pred_l=[] \n",
        "while(i<len(Pred)):   \n",
        "  Y_test_l.append(int(np.argmax(Y_test[i])))     \n",
        "  Pred_l.append(int(np.argmax(Pred[i])))   \n",
        "  i+=1\n",
        "report=classification_report(Y_test_l, Pred_l)"
      ],
      "metadata": {
        "id": "ZSF6wfr06lOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_image(ind,images_f,images_f_2,Model):\n",
        "  cv2_imshow(images_f[ind])\n",
        "  image_test=images_f_2[ind]\n",
        "  print(\"Label actual:  \" + Exp[labels[ind]]  )\n",
        "  pred_1=Model.predict(np.array([image_test]))\n",
        "  #print(pred_1)\n",
        "  pred_class=Exp[int(np.argmax(pred_1))]\n",
        "  print(\"Predicted Label: \"+ pred_class)\n"
      ],
      "metadata": {
        "id": "x8eg5SoJ6z99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "ages=[]\n",
        "genders=[]\n",
        "images=[]\n",
        "for fle in files:\n",
        "  age=int(fle.split('_')[0])\n",
        "  gender=int(fle.split('_')[1])\n",
        "  total=fldr+'/'+fle\n",
        "  print(total)\n",
        "  image=cv2.imread(total)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image= cv2.resize(image,(48,48))\n",
        "  images.append(image)\n",
        "  ages.append(age)\n",
        "  genders.append(gender)"
      ],
      "metadata": {
        "id": "Ev7IlzD-62YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=[]\n",
        "i=0\n",
        "while i<len(ages):\n",
        "  label=[]\n",
        "  label.append([ages[i]])\n",
        "  label.append([genders[i]])\n",
        "  labels.append(label)\n",
        "  i+=1\n"
      ],
      "metadata": {
        "id": "vw526PAh66N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_f=np.array(images)\n",
        "labels_f=np.array(labels)\n",
        "images_f_2=images_f/255\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(images_f_2, labels_f,test_size=0.25)"
      ],
      "metadata": {
        "id": "X-zFxEeT7CX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train[0:5]\n",
        ">>array([[[36],\n",
        "        [ 0]],\n",
        "       [[50],\n",
        "        [ 0]],\n",
        "       [[65],\n",
        "        [ 0]],\n",
        "       [[ 3],\n",
        "        [ 0]],\n",
        "       [[25],\n",
        "        [ 1]]])"
      ],
      "metadata": {
        "id": "H_D60D5_7DXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_2=[Y_train[:,1],Y_train[:,0]]\n",
        "Y_test_2=[Y_test[:,1],Y_test[:,0]]\n"
      ],
      "metadata": {
        "id": "MkoybpdB7IMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_2[0][0:5]\n",
        ">>array([[0],\n",
        "       [0],\n",
        "       [0],\n",
        "       [0],\n",
        "       [1]])\n",
        "Y_train_2[1][0:5]\n",
        ">>array([[36],\n",
        "       [50],\n",
        "       [65],\n",
        "       [ 3],\n",
        "       [25]])"
      ],
      "metadata": {
        "id": "aUSEE7_U7QHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n",
        "from tensorflow.keras.layers import Input,Activation,Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "def Convolution(input_tensor,filters):\n",
        "    \n",
        "    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001))(input_tensor)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x= Activation('relu')(x)\n",
        "    return x\n",
        "def model(input_shape):\n",
        "  inputs = Input((input_shape))\n",
        "  \n",
        "  conv_1= Convolution(inputs,32)\n",
        "  maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)\n",
        "  conv_2 = Convolution(maxp_1,64)\n",
        "  maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)\n",
        "  conv_3 = Convolution(maxp_2,128)\n",
        "  maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)\n",
        "  conv_4 = Convolution(maxp_3,256)\n",
        "  maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)\n",
        "  flatten= Flatten() (maxp_4)\n",
        "  dense_1= Dense(64,activation='relu')(flatten)\n",
        "  dense_2= Dense(64,activation='relu')(flatten)\n",
        "  drop_1=Dropout(0.2)(dense_1)\n",
        "  drop_2=Dropout(0.2)(dense_2)\n",
        "  output_1= Dense(1,activation=\"sigmoid\",name='sex_out')(drop_1)\n",
        "  output_2= Dense(1,activation=\"relu\",name='age_out')(drop_2)\n",
        "  model = Model(inputs=[inputs], outputs=[output_1,output_2])\n",
        "  model.compile(loss=[\"binary_crossentropy\",\"mae\"], optimizer=\"Adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "dWCvgNiZ7V81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint import tensorflow as tf\n",
        "fle_s='Age_sex_detection.h5'\n",
        "checkpointer = ModelCheckpoint(fle_s, monitor='val_loss',verbose=1,save_best_only=True,save_weights_only=False, mode='auto',save_freq='epoch')\n",
        "Early_stop=tf.keras.callbacks.EarlyStopping(patience=75, monitor='val_loss',restore_best_weights=True),\n",
        "callback_list=[checkpointer,Early_stop]\n",
        "History=Model.fit(X_train,Y_train_2,batch_size=64,validation_data=(X_test,Y_test_2),epochs=500,callbacks=[callback_list])"
      ],
      "metadata": {
        "id": "CJg8opuU7afq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_image(ind,images_f,images_f_2,Model):       cv2_imshow(images_f[ind])   \n",
        "image_test=images_f_2[ind]   pred_1=Model.predict(np.array([image_test]))  \n",
        "#print(pred_1)   \n",
        "sex_f=['Male','Female']   \n",
        "age=int(np.round(pred_1[1][0]))   \n",
        "sex=int(np.round(pred_1[0][0]))   \n",
        "print(\"Predicted Age: \"+ str(age))   \n",
        "print(\"Predicted Sex: \"+ sex_f[sex])"
      ],
      "metadata": {
        "id": "2K8Yo1e17gRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L-nAZK6V7kyS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}